## 實作五

## Impala (5) : EXTERNAL TABLE 外部資料表

### 準備 HDFS 資料

前面幾個例子，Impala 的資料表都是存放於 Hive 預設的 HDFS 路徑（以 Etu Virtual Appliance 為例，設定值為 /hive/warehouse）。能否直接用使用者自己的 HDFS 家目錄當作特定資料表的存放路徑呢？答案是可以的。作法是在建立資料表時，使用 EXTERNAL 這個關鍵字。

首先，讓我們先在 HDFS 家目錄放一些測試資料，並且用這個例子來解決上一個 PARTITION 實作遇到的權限問題：

<small><pre>
hadoop fs -mkdir -p logs
hadoop fs -mkdir -p logs/year=2014/month=11/day=30/host=host1
hadoop fs -mkdir -p logs/year=2014/month=11/day=30/host=host2
hadoop fs -mkdir -p logs/year=2014/month=12/day=01/host=host1
hadoop fs -mkdir -p logs/year=2014/month=12/day=01/host=host2
hadoop fs -mkdir -p logs/year=2014/month=12/day=02/host=host1
hadoop fs -mkdir -p logs/year=2014/month=12/day=02/host=host2
echo "FTP,192.168.70.10,/home/jazz/test1.log" | hadoop fs -put - logs/year=2014/month=11/day=30/host=host1/data
echo "FTP,192.168.70.11,/home/jazz/test2.log" | hadoop fs -put - logs/year=2014/month=11/day=30/host=host2/data
echo "FTP,192.168.70.10,/home/jazz/test1.log" | hadoop fs -put - logs/year=2014/month=12/day=01/host=host1/data
echo "FTP,192.168.70.11,/home/jazz/test2.log" | hadoop fs -put - logs/year=2014/month=12/day=01/host=host2/data
echo "FTP,192.168.70.10,/home/jazz/test1.log" | hadoop fs -put - logs/year=2014/month=12/day=02/host=host1/data
echo "FTP,192.168.70.11,/home/jazz/test2.log" | hadoop fs -put - logs/year=2014/month=12/day=02/host=host2/data
</pre></small>

### 建立 EXTERNAL TABLE

接著，讓我們進入 impala-shell，並使用 `CREATE EXTERNAL TABLE <資料表名稱> LOCATION <HDFS 路徑>` 的語法來建立外部資料表：

<small><pre>
CREATE DATABASE ext;
CREATE EXTERNAL TABLE ext.logs (field1 STRING, field2 STRING, field3 STRING)
    PARTITIONED BY (year STRING, month STRING, day STRING, host STRING)
    ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    LOCATION '/user/eva/logs';
</pre></small>

### 動態新增 PARTITION

<small><pre>
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="11", day="30", host="host1" );
SELECT * FROM ext.logs;
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="11", day="30", host="host2" );
SELECT * FROM ext.logs;
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="12", day="01", host="host1" );
SELECT * FROM ext.logs;
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="12", day="01", host="host2" );
SELECT * FROM ext.logs;
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="12", day="02", host="host1" );
SELECT * FROM ext.logs;
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="12", day="02", host="host2" );
SELECT * FROM ext.logs;
</pre></small>

### 在已存在的 PARTITION 目錄中新增資料

在已經存在的 PARTITION 目錄中新增資料，就可以在 SELECT 結果中看到新的紀錄。請在 SHELL 環境中執行以下指令：

<small><pre>
echo "FTP,192.168.70.13,/home/jazz/test3.log" | hadoop fs -put - logs/year=2014/month=12/day=02/host=host2/data2
</pre></small>

請在 impala-shell 中執行以下查詢：

<small><pre>
SELECT * FROM ext.logs;
</pre></small>

結果如以下所示：
<small><pre>
[etu-master.etudomain.com:21000] > SELECT * FROM ext.logs;
Query: select * FROM ext.logs
+--------+---------------+----------------------+------+-------+-----+-------+
| field1 | field2        | field3               | year | month | day | host  |
+--------+---------------+----------------------+------+-------+-----+-------+
| FTP    | 192.168.70.10 | /home/jazz/test1.log | 2014 | 12    | 02  | host1 |
| FTP    | 192.168.70.11 | /home/jazz/test2.log | 2014 | 12    | 02  | host2 |
| FTP    | 192.168.70.13 | /home/jazz/test3.log | 2014 | 12    | 02  | host2 |
| FTP    | 192.168.70.11 | /home/jazz/test2.log | 2014 | 11    | 30  | host2 |
| FTP    | 192.168.70.10 | /home/jazz/test1.log | 2014 | 11    | 30  | host1 |
| FTP    | 192.168.70.11 | /home/jazz/test2.log | 2014 | 12    | 01  | host2 |
| FTP    | 192.168.70.10 | /home/jazz/test1.log | 2014 | 12    | 01  | host1 |
+--------+---------------+----------------------+------+-------+-----+-------+
Returned 7 row(s) in 0.20s
</pre></small>

### 小心權限問題

預設 PARTITION 是以『啟動 Impala 的身份』當作 Owner，因此，如果您在 HDFS 目錄不存在的時候，呼叫 `ALTER TABLE ... ADD PARTITION` 那就會產生一個新的子目錄，卻無法寫入新的資料。

請在 impala-shell 中輸入以下語法：

<small><pre>
ALTER TABLE ext.logs ADD PARTITION ( year="2014", month="12", day="30", host="host1" );
</pre></small>

請在 Shell 中輸入以下指令：

<small><pre>
hadoop fs -ls -R logs
</pre></small>

您會看到如下的結果：

<small><pre>
eva@etu-master ~ $ hadoop fs -ls -R logs
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=11
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=11/day=30
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=11/day=30/host=host1
-rw-------   3 eva eva         39 2014-12-24 11:20 logs/year=2014/month=11/day=30/host=host1/data
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=11/day=30/host=host2
-rw-------   3 eva eva         39 2014-12-24 11:20 logs/year=2014/month=11/day=30/host=host2/data
drwx------   - eva eva          0 2014-12-24 11:42 logs/year=2014/month=12
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=12/day=01
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=12/day=01/host=host1
-rw-------   3 eva eva         39 2014-12-24 11:20 logs/year=2014/month=12/day=01/host=host1/data
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=12/day=01/host=host2
-rw-------   3 eva eva         39 2014-12-24 11:20 logs/year=2014/month=12/day=01/host=host2/data
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=12/day=02
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=12/day=02/host=host1
-rw-------   3 eva eva         39 2014-12-24 11:20 logs/year=2014/month=12/day=02/host=host1/data
drwx------   - eva eva          0 2014-12-24 11:20 logs/year=2014/month=12/day=02/host=host2
-rw-------   3 eva eva         39 2014-12-24 11:20 logs/year=2014/month=12/day=02/host=host2/data
drwx------   - etu eva          0 2014-12-24 11:42 logs/year=2014/month=12/day=30
ls: Permission denied: user=eva, access=READ_EXECUTE, inode="/user/eva/logs/year=2014/month=12/day=30":etu:eva:drwx------
</pre></small>

意味著多了 /user/eva/logs/year=2014/month=12/day=30 可是卻無法讀取，因為目錄擁有者是執行 impalad 的身份。

**<結論>** 若有權限問題，請先增加 HDFS 資料，才動態增加 PARTITION !!

### 統計 PARTITION 個數

既然可以動態增加 PARTITION，久而久之，如何檢查目前有多少個 PARTITION 呢？您可以使用實作二所提到的幾個指令，才得到對應的結果：

<small><pre>
COMPUTE STATS ext.logs;
SHOW TABLE STATS ext.logs;
SHOW COLUMN STATS ext.logs;
</pre></small>

### 參考資料

1. [Impala Tutorial](http://www.cloudera.com/content/cloudera/en/documentation/cloudera-impala/latest/topics/impala_tutorial.html)
1. [CREATE TABLE Statement](http://www.cloudera.com/content/cloudera/en/documentation/cloudera-impala/latest/topics/impala_create_table.html)
1. [ALTER TABLE Statement](http://www.cloudera.com/content/cloudera/en/documentation/cloudera-impala/latest/topics/impala_alter_table.html)

--------------------
本文件最後更新於：<script>document.write(document.lastModified);</script>
